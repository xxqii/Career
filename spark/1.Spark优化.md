### 开发调优

* 避免创建重复的RDD
  在开发Spark作业时，首先基于数据源创建一个初始的RDD；接着对RDD进行不同的算子操作（例如：map、reduce等），得到最终的结果。RDD的转换流程就是RDD的血缘关系。对于同一个RDD只创建一个RDD，避免重复创建RDD。
* 尽可能复用同一个RDD
  对RDD执行不同的算子操作时要尽可能的复用一个RDD，例如：有一个RDD的数据格式是key-value类型的，另一个是value类型的。而且value数据是完全一样的，那么此时我们可以只使用key-value的RDD。
* 对多次使用的RDD进行持久化
  Spark对一个RDD执行多次算子操作的原理是：每次对RDD执行算子操作，都会从源头处重新计算一遍，然后执行算子操作，性能较差。对多次使用的RDD持久化，可以避免从源头重新计算的过程。常用的持久化级别例如：MEMORY_ONLY、MEMORY_AND_DISK、MEMORY_ONLY_SER、MEMORY_AND_DISK_SER、DISK_ONLY。
  * MEMORY_ONLY：消耗内存，如果数据比较多，可能造成JVM OOM内存溢出。
  * MEMORY_ONLY_SER：将RDD序列化，每个partition仅仅是一个字节数组而已，减少对象数量，降低内存使用。
  * MEMORY_AND_DISK_SER：该策略会尽量尝试将数据缓存在内存中，内存缓存不下才会写入磁盘。
* 尽量避免使用shuffle类算子
  为Spark作业运行过程中，最消耗性能的地方就是shuffle过程。将集群中多个节点的同一个key，拉取到同一个节点上，进行聚合或join操作。例如：reduceByKey、join、distinct、repartition等。
  shuffle过程中，各个节点相同的key都会先写入本地磁盘文件中，其它节点通过网络传输拉取磁盘文件中相同的key，然后对key进行聚合。聚合的时候可能由于key过多，内存不够存放，进而溢出到磁盘文件中，可能造成大量的磁盘IO。
* 使用map-side的预聚合的shuffle操作
  每个节点对本地相同的key进行一次聚合操作，类似MapReduce中本地combiner。map-side预聚合后，每个节点本地只有一条相同的key，其它节点拉取所有节点相同的key时，就大大减少需要拉取的数据量，从而减少网络IO和磁盘IO。尽量使用reduceByKey和aggregateByKey算子替换掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地相同的key进行聚合，而groupByKey不会进行聚合的。
* 使用高性能的算子
  1. 使用reduceByKey和aggregateByKey替换groupByKey；
  2. 使用mapPartitions代理map；（mapPartitions一次处理一个partition的所有数据，而不是一次调用处理一条，性能较高。如果处理的数据太多可能出现OOM）
  3. 使用foreachPartitions替代foreach；（比如批量写数据库）
  4. 使用filter后进行coalesce操作；（如果filter过滤数据较多，每个task处理的数据较少，浪费资源，而且task越多可能速度反而越慢。采用coalesce减少partition数量，可能会提升性能）
  5. repartitionAndSortWithinPartitions替代repartition与sort类操作；（一边shuffle一边sort，比先shuffle再sort性能要高）；
* 广播大变量
  Spark算子中使用外部变量（尤其是大变量），默认情况下Spark会将变量复制多个副本通过网络传输到task中，每个task一个副本。副本通过网络传输会有性能开销，可能造成Excutor占用过多内存导致频繁GC，极大影响性能。通过广播变量，可以将变量发送到每个Executor中，多个task可以共享一个副本。避免网络开销，降低Executor内存使用。
* 使用kryo优化序列化性能
  Spark中使用到序列化的地方主要包括：算子中使用外部变量，外部变量会序列化进行网络传输；自定义对象作为RDD泛型时，自定义对象都会进行序列化；使用序列化的持久化策略时，spark将每个partition序列化为字节数组持久化。spark默认使用java序列化（ObjectOutputStream），kryo序列化比java序列化性能高10倍左右。
* 优化数据结构
  java对象的对象头、引用等额外信息；字符串定义的长度等额外信息，集合内部元素的封装等等都会消耗额外的内存空间。spark建议尽量使用字符串代替对象、使用原始类型代替字符串、使用数组代替集合。降低内存占用。（可能造成后期维护比较困难）

### 资源参数调优

&emsp; spark的参数可以在spark-submit中设置，如果参数设置过小，不能充分利用集群资源，如果设置过大，可能造成资源浪费。spark-submit提交应用后，应用会启动一个对应的Driver进程，根据部署模式不同，Driver进程可能在本地，也可能在集群中的某个节点上启动。Driver进程本身会占用一定数量的cpu和内存。Driver进程会向ResourceManager申请作业需要的资源（Executor进程），yarn集群根据我们设置的资源参数，在各个工作节点上启动一定数量的executor进程，每个executor进程都会占用一定数量的内存和cpu。

&emsp;获取到资源后，Driver进程开始调度和执行作业代码。Driver进程将作业分成多个stage，每个stage创建一批task，然后将task分配到各个Executor执行，task是最小的计算单元，每个stage中task执行逻辑一样（只是处理的partiton不同，数据不同）。一个stage的task执行完毕之后，会在各个节点的本次磁盘写入计算中间结果，然后Driver调度运行下一个stage。下一个stage的task数量就是上一个stage输出的中间结果。如此循环，直到代码逻辑全部执行完毕。

&emsp; Spark是根据shuffle类算子类进行stage的划分，每个stage在执行的时候都会从上一个stage的task所在节点通过网络IO的方式拉取自己处理的所有key。如果task中调用了persist算子，task的结果也会保存在Executor进程的内存中或者磁盘上。

&emsp; Executor内存主要分为三块，第一块是task执行逻辑使用，默认占Executor总内存的20%；第二块是shuffle过程中stage拉取上一个stage的执行结果进行聚合操作使用，默认占Executor总内存的20%；第三块是RDD持久化时使用，默认占Executor内存的60%。Task执行速度跟每个Executor进程的cpu数量有直接关系，一个cpu同一时间只能执行一个线程，每个Executor进程上分配多个task，都是以每个task一条线程的方式，并发执行的。如果cpu比较充足，可以高效的执行完分配的task。

资源参数调优如下：

* num-executors：设置Spark作业总共多少个Executor进程，Driver向ResourceManager申请资源时，会按照设置的参数，在Worker节点上启动相应数量的Executor进程。（建议每个作业一般设置50~100个Executor）
* executor-memory：每个Executor进程的内存，如果设置太小可能发生OOM异常。（num-executors * executor-memory 一般为队列资源的1/2 ~ 1/3左右，避免占用过多资源，别的作业无法执行）
* executor-cores：设置每个Executor进程的cpu数量，决定了每个Executor并发执行task数，cpu越多，并发执行的task数量越多。（设置2~4个比较合适，可以参考队列总cpu数和num-executors数， num-executors * executor-cores 一般为队列资源的1/2 ~ 1/3）
* driver-memory：设置Driver进程内存。（一般不设置，如果使用collect算子将RDD的全局全部拉取到Driver上进行处理，需要确保Driver内存足够大，否则出现Driver出现OOM）
* spark.default.parallelism：设置每个stage默认task数量。（task数量一般设置500 ~ 1000个较为合适，可以设置为num-executors * executors-core的2 ~ 3倍）如果不设置Spark根据底层HDFS中block数量来设置task数量，默认一个block对应一个task。
* spark.storage.memoryFaction：Executor中持久化占用内存比例，默认60%。如果有较多的RDD持久化操作，该参摄可以适当提高一些，保证持久化可以在内存中完成；如果shuffle操作比较多，持久化操作比较少，可以适当降低此参数值；如果发现作业由于频繁的GC导致运行缓慢，意味着task执行用户代码的内存不够用，同样可以调低此参数。
* spark.shuffle.memoryFraction：stage拉取上一个stage的输出，聚合数据的时候能够使用的Executor内存比例，默认0.2。如果shuffle过程中数据超出了20%的内存则会溢出到磁盘，降低shuffle性能。

spark参数调优如下所示：

> ./bin/spark-submit \
> --master yarn-cluster \
> --num-executors 100 \
> --executor-memory 6G \
> --executor-cores 4 \
> --driver-memory 1G \
> --conf spark.default.parallelism=1000 \
> --conf spark.storage.memoryFraction=0.5 \
> --conf spark.shuffle.memoryFraction=0.3 \
>
> ### 数据调优
>
> &emsp; 数据调优主要分为两个部分：数据倾斜于shuffle调优。
>
> #### 数据倾斜
>
> * 现象
>   绝大多数task执行非常快，单个别task执行极慢；原本能够正常执行的作业，某天突然爆出OOM异常；
> * 原理
>   在作业中不同stage进行shuffle操作的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key聚合或者join操作等。如果某个key对应的数据量比较大，就会发生数据倾斜。spark作业中stage运行进度是由时间最长的那个task决定的。因此出现数据倾斜的时候，spark作业看起来运行非常缓慢，甚至可能因为某个task处理的数据量过大导致内存溢出。
> * 问题定位
>   数据倾斜只发生在shuffle过程中，常见的shuffle算子包括：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition。
>   首先定位数据倾斜发生的stage，在yarn-cluster模式下，可以通过spark web ui快速查看当前运行到第几个stage，stage内task个数和各个task分配的数据量。通过stage定位到代码中对应的shuffle算子。
>   查看发生数据倾斜的RDD中key的分布情况，查看key的数据量。
> * 解决方案
>   1. 过滤少数导致倾斜的key
>      如果倾斜的key对计算结果不重要可以直接过滤掉对应的key。可以使用sample算子对RDD采样，计算每个key的数量，取数量最多的几个key过滤即可。（例如：刷号渠道过滤。治标不治本，没有根本上解决数据倾斜）
>   2. 提高shuffle操作的并行度
>      在执行shuffle算子的时候，设置一个比较大的partitions，增加shuffle read task数量，可以让原本分配给一个task的多个key分配给多个task，让每个task处理更少的数据。（适用与每个key的数据量差别不大，但是shuffle后多个key汇聚到同一个task。没有根本上解决数据倾斜）
>   3. 两阶段聚合
>      第一阶段给每个key打上一个随机数，比如10以内的随机数，这样相同的key就变得不一样了，shuffle后会分配给不同的task，shuffle后的task接收数据后先做一次聚合，然后去掉随机数再做一次聚合。这样就得到了最终结果。（极大的解决了数据倾斜问题；仅适用于聚合类的shuffle操作，join类的shuffle不适用）
>   4. 将reduce join转化为map join
>      在使用join算子时，如果操作中的一个RDD或者表比较小，将较小的RDD使用collect拉取到内存中，使用Broadcast广播变量，然后结合map操作实现join操作。完全避免shuffle操作，彻底避免数据倾斜的发生和出现。（只适用与join操作导致的数据倾斜，并且join操作有一边的数据比较小，可以从根本上解决数据倾斜；需要消耗Driver和Executor内存，如果广播的数据比较大，可能造成Executor进程OOM）
>   5. 采样倾斜key并分拆join操作
>      如果join操作的时候两个RDD（或表）的数据量都比较大，可以看下RDD（或表）中key的分布情况，如果数据倾斜是因为某一个RDD(或表)中少数key数据量过大，而两一个RDD(或表)key分布比较均匀的时候。对少数几个数据量过大key的RDD通过sample算子采样，统计每个key的数量，获取数量较大的key。将这几个key对应的数据从以前需要join的两个RDD中拆分出来形成两个单独的RDD，在数据量比较大的RDD一方添加N以内的随机前缀，在数据量比较均匀一方的RDD附加一个0 ~ N的前缀，将数据膨胀N倍，然后进行join操作。最后将两份RDD的操作结果union合并即可。（如果导致数据倾斜的key比较多，数据膨胀较大不合适）
>   6. 随机前缀 + 扩容RDD进行join
>      如果数据倾斜的key比较多，分拆key没有意义。可以对数据倾斜的RDD添加随机前缀，数据分布均匀的RDD扩容N倍的方式进行join。（扩容数据较多，需要更大的内存）

#### shuffle调优

&emsp; 大多数spark作业的性能主要消耗在了shuffle环节，该环节包括大量的磁盘IO、网络IO等。shuffle优化占到调优中的一小部分，主要的优化还是：代码开发、资源调优、数据倾斜。

* HashShuffleManager：spark1.2版本之前默认shuffle计算引擎（产生大量的磁盘文件，进而有大量的磁盘IO）。
  &emsp;stage结束的时候每个task按照key的hash值进行分类，相同的key写入同一个磁盘文件（先写磁盘缓冲，缓冲满写文件，文件的数量由下游task数量确定），每个文件属于下游的某一个task。下游task执行的时候先进行shuffle read操作，将不同节点上属于自己的文件拉取到buffer中进行聚合。
  * spark.shuffle.consolidateFiles：默认为false，如果设置为true，shuffle write的时候task不会为下游的每个task生成一个文件，此时会出现shuffleFileGroup概念，每个shuffleFileGroup对应一批磁盘文件，文件数目和下游task数量一致。不同批次的task可以共享一个shuffleFileGroup，大大减少了磁盘文件数量。
* SortShuffleManager：spark1.2以后版本默认计算引擎（产生较多的临时磁盘文件，最后将所有临时文件合并成一个磁盘文件。拉取数据时根据索引读取每个磁盘文件中的部分数据即可）。
  shuffle write的时候会将数据写入内存中的buffer（如果时reduceBykey这种聚合操作，写入的时HashMap结构，如果时join类型的操作，则使用Array数据结构），数据写入buffer后会判断是否达到阈值，如果达到阈值则将buffer中的数据写入磁盘。写入磁盘前会对内存数据结构中的数据进行排序，然后分批次写入磁盘（默认每个批次10000条）。task将所有数据写入内存过程中会发生多次溢出，产生多个临时文件，最后会将之前的临时文件合并、排序，写入最终的磁盘文件，一个task对应一个磁盘文件，大大减少了磁盘文件数量。还会生成一个索引文件，标记了下游每个task数据在文件中的start offset和end offset。
  * spark.shuffle.file.buffer：默认值32k，该参数用于设置shuffle write task的BufferedOutputStream的buffer缓冲大小。将数据写到磁盘文件之前，会先写入buffer缓冲中，待缓冲写满之后，才会溢写到磁盘。
  * spark.reducer.maxSizeInFlight：默认值48m，该参数用于设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据。
  * spark.shuflle.io.maxRetries：默认值3，shuffle read task从shuffle write task所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取还是没有成功，就可能会导致作业执行失败。
  * spark.shuffle.io.retryWait：5s，该参数代表了每次重试拉取数据的等待间隔，默认是5s。
  * spark.shuffle.memoryFraction：0.2，该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。
  * spark.shuffle.manager：sort，该参数用于设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。HashShuffleManager是Spark 1.2以前的默认选项，但是Spark 1.2以及之后的版本默认都是SortShuffleManager了。tungsten-sort与sort类似，但是使用了tungsten计划中的堆外内存管理机制，内存使用效率更高。
  * spark.shuffle.sort.bypassMergeThreshold：200，当ShuffleManager为SortShuffleManager时，如果shuffle read task的数量小于这个阈值（默认是200），则shuffle write过程中不会进行排序操作，而是直接按照未经优化的HashShuffleManager的方式去写数据，但是最后会将每个task产生的所有临时磁盘文件都合并成一个文件，并会创建单独的索引文件。
  * spark.shuffle.consolidateFiles：false，如果使用HashShuffleManager，该参数有效。如果设置为true，那么就会开启consolidate机制，会大幅度合并shuffle write的输出文件，对于shuffle read task数量特别多的情况下，这种方法可以极大地减少磁盘IO开销，提升性能。

#### 动态分配

&emsp;动态分配值基于Executors的，如果task执行过程由数据倾斜或者数据由高峰和低谷，如果设置固定数量的executors，可能造成大量的executors空闲，浪费集群资源。可以设置动态资源分配，在executors空闲一定时间后，主动回收executors资源。动态分配默认不开启，并且在设置了num-executors后动态分配不再生效。

使用场景：
&emsp; 在hive-cli查询数据时，只有当用户执行了hive sql，才会向yarn申请资源，如果不提交sql，只是一个本地jvm进程，不消耗yarn资源。当使用spark-sql的时候，如果启动spark-sql指定了-num-executors数量，那么从spark-sql命令启动时候就已经分配了固定数量的executors，而且会一直被占用着，只有用户退出spark-sql的时候才会释放。spark-sql on yarn在spark1.2开始支持资源动态分配。非常适合spark-sql on yarn以及spark-sql作为长时间服务来使用的场景。

配置：

* spark.dynamicAllocation.enabled：false，设置为true开启动态分配功能；
* spark.dynamicAllocation.executorIdleTimeout：executor空闲时间，如果超时则executor被删除回收；
* spark.dynamicAllocation.cachedExecutorIdleTimeout：executor里cache数据超时设置；
* spark.dynamicAllocation.initialExecutors：初始executors数量；
* spark.dynamicAllocation.maxExecutors：最大executors数量；
* spark.dynamicAllocation.minExecutors：最小executors数量；
* spark.dynamicAllocation.executorAllocationRatio：默认根据task数量分配最大数量的executors来最大化并行性；但是对于小任务，启动executors的开销比执行task的开销更大，申请过多executors可能浪费资源。次设置用于减少executors完全并行的比例。例如：设置为0.5，总共由100个task，则需要申请的executors需要同时执行50个task。
* spark.dynamicAllocation.schedulerBacklogTimeout：任务积压多长时间后申请新的executors。

注意事项：

1. 资源申请方式：spark申请executor是轮询的方式，第一次添加一个，第二次添加2,4,8等，其实就和tcp的慢启动快增长一致。
2. 需要在yarn的NodeManager中配置spark_shuffle，并指定shuffle class为：org.apache.spark.network.yarn.YarnShuffleService。

3. executors中cache数据的清理：默认情况下含有cache数据的executors不会被清理，当配置了spark.dynamicAllocation.cachedExecutorIdleTimeout可以控制含有cache的executors是否可以被清理，cache data应该保存在off-heap中避免被回收。

4. shuffle数据的删除：在fhuffle阶段executors需要将shuffle数据映射到磁盘上，如果某一个task执行比较慢，在次期间其他executors已经超时被删除了，那么会造成数据需要重新计算。为了解决次问题，需要使用一个external shuffle service，shuffle service独立与executors和application，spark executros从此服务获取shuffle数据。



### Blog

<https://tech.meituan.com/2016/04/29/spark-tuning-basic.html>  

<https://tech.meituan.com/2016/05/12/spark-tuning-pro.html>