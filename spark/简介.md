### Spark执行流程

1. spark-submit提交
   * spark-submit提交任务，执行exec "${SPARK_HOME}"/bin/spark-class org.apache.spark.deploy.SparkSubmit "$@"，任务提交时通过SparkSubmit类执行的；
   * 在SparkSubmit的main方法中会调用submit方法来提交作业；然后执行runMain方法；
   * SparkSubmit的runMain方法：addJarToClasspath（添加jar到类路径）、通过反射获取mainClass和mainMethod、通过反射机制执行mainMethod
2. Application main方法执行
   * 构建SparkConf和SparkContext；
     在SparkContext创建时会执行： _jobProgressListener（监听Job执行情况）、createSparkEnv(准备环境)、_hadoopConfiguration（hadoop环境）、添加用户jar包和资源文件、创建taskScheduler、创建dagScheduler（分割stage、）；启动_taskScheduler（任务的开始、提交、停止、取消等监控）、dynamicAllocationEnabled判断是否需要动态分配。
   * 当遇到action操作的时候会调用

### RDD

* 创建 RDD 对象 
* DAGScheduler模块介入运算，计算RDD之间的依赖关系。RDD之间的依赖关系就形成了DAG
* .每一个JOB被分为多个Stage，划分Stage的一个主要依据是当前计算因子的输入是否是确定的，如果是则将其分在同一个Stage，避免多个Stage之间的消息传递开销。

RDD依赖：

&emsp;RDD依赖关系构成了rdd的血统，同时也生成了逻辑上的DAG。每一个RDD都可以依据依赖关系一级一级向前回溯重新计算，这便是spark rdd容错机制。（在部分数据丢失时，可以通过依赖关系重新计算丢失数据的分区，而不需要计算所有分区。如果是shuffer后的分区数据丢失呢，需要计算所有分区数据吗？）

* 窄依赖：parent RDD中的每个Partition最多被child RDD中的一个Partition使用。例如：map、union
* 宽依赖：parent RDD中的每个Partition被child RDD中的多个Partition使用，这时会依据Record的key进行数据重组，这个过程即为Shuffle（洗牌）。例如：reduceByKey，groupByKey

### Job & Stage

* Job：在一个Application中以action为边界划分job，spark采用惰性机制，对RDD的创建和转化不会立即执行，只有遇到第一个action的时候才会执行；一个Job包含多个Transfer操作和一个Action操作；
* shuffer：在处理RDD宽依赖的时候，parent RDD所有分区里的数据都需要进行洗牌，数据打散重组。例如：join、reduceByKey、groupByKey等操作。

* Stage：在一个job内按照shuffle为边界划分出不同的Stage（由于Shuffle的存在，不同的Stage是不能并行计算的，因为后面Stage的计算需要前面Stage的Shuffle的结果），在一个Stage内，所有的操作以串行的Pipeline的方式，由一组Task完成计算。
* Task：对一个Stage之内的RDD进行串行操作的计算任务，每个Stage由一组并发的Task组成（即TaskSet），这些Task的执行逻辑完全相同，只是作用域不同的Partition。一个Stage的总Task个数由Stage中最后一个RDD的partition个数决定。（Driver会根据Task操作数据的位置分配给相应的Executor，尽量减少数据的移动）一个Executor内同一时刻可以并行执行的Task数由`总CPU数／每个Task占用的CPU数`决定，即`spark.executor.cores / spark.task.cpus`。Task分为ShuffleMapTask和ResultTask两种，位于最后一个Stage的Task为ResultTask，其他阶段的属于ShuffleMapTask。

### Persist & Check Point

* Persist：将RDD持久化到内存或者硬盘，cache方法则是缓存到内存中。通过persist可以避免rdd多次使用的时候被多次执行。
* Check Point：将RDD保存到外部存储中，例如：硬盘、hdfs等。如果Persist后的rdd数据丢失或被替换，则Check Point可以发挥作用，避免重新计算。

&emsp;一个Job在开始处理RDD的partition时，准确点说，在Executor中运行的Task在获取Partition数据时，会先判断是否被持久化，如果没有命中则判断是否保存了checkpoint，如果没有则会重新计算该Partition。

### SparkContext

&emsp;用户逻辑和Spark集群交互的接口，会和Master交互，包括向它申请计算资源等。Spark执行每个Application的时候会启动Driver和Executor两种jvm进程。SparkContext会分隔Stage，并由Stage构建DAG图。在Stage内部根据partition，将stage分解为Task，并把Taskset发送给TaskScheduler。Executor向SparkContext申请Task，TaskScheduler将Task发放给Executor运行同时SparkContext将应用程序代码发放给Executor。

* Driver：执行Application中的main方法，提交Job，将Job转化为Task，在各个Executor进程间协调Task的调度。Client部署时Driver运行在Client端，Cluster部署时运行在Worker节点的Executor进程内。
* Executor：运行在Work上的Executor进程负责执行Task，并将结果返回给Driver。同时为需要缓存的RDD提供存储功能。

* DAGScheduler：DAGScheduler 把一个Spark作业转换成Stage的DAG（Directed Acyclic Graph有向无环图），根据RDD和Stage之间的关系找出开销最小的调度方法，然后把Stage以TaskSet的形式提交给 TaskScheduler
* TaskScheduler：TaskScheduler维护所有TaskSet，当Executor向Driver发送心跳时，TaskScheduler会根据其资源剩余情况分配 相应的Task。另外TaskScheduler还维护着所有Task的运行状态，重试失败的Task。

### 算子

* map
* filter
* flatMap
* mapPartitions
* mapPartitionsWithIndex
* union
* distinct
* groupByKey
* reduceByKey
* sortByKey
* join
* repartition

### Introduce

* Driver
* Executor
* Partitioner
  * HashPartitioner： key.hashCode % numPartitions
  * RangePartitioner：

### Executor

### 运行模式

* standalone 
  Spark实现的资源调度框架，其主要的节点有Client节点、Master节点和Worker节点。当用spark-shell交互式工具提交Spark的Job时，Driver在Master节点上运行；当 使用spark-submit工具提交Job时，Driver是运行在本地 Client端上的。	

